<!DOCTYPE html><html><body><ul><li>CoFI - Common Framework for Inference</li><li>&nbsp;&nbsp;&nbsp;Parameter estimation</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Matrix based solvers</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linear system solvers</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('linear_regression_linear_system_general.py', 'cofi-examples/examples\\linear_regression\\linear_regression_linear_system_general.py', 'Polynomial Linear regression solved by linear system solver (with uncertainty)\n\nThis file sets up an example from setting up problem to running the inversion:\n- For the problem: polynomial linear regression,\n- Using the tool: linear system solver (scipy.linalg.lstsq)\n\nThe difference between this script and linear_regression_linear_system_solver.py\nis that this one takes uncertainty into account, by adding a data covariance matrix.\nThe underlying solver is still scipy.linalg.lstsq, but the formulea passed into it\nare different, as will be explained in the following paragraphs.\n\nThe function we are going to fit is: y = -6 - 5x + 2x^2 + x^3\n\nWe may also write the polynomial curves in this form: y = sum(m_n * x^n), n=0,1,2,3,\nwhere: m_n, n=0,1,2,3 are the model coefficients.\n\nIf we consider N data points and M=3 model parameters, then N equations like above \nyields a linear operation: d = Gm,\nwhere: d refers to data observations (y_1, y_2, ..., y_N).T\n       G refers to basis matrix: ( (1, x_1, x_1^2, x_1^3)\n                                   (1, x_2, x_2^2, x_2^3)\n                                   ...\n                                   (1, x_N, x_N^2, x_N^3) )\n       m refers to the unknown model parameters (m_0, m_1, m_2, m_3)\n\nNote that G matrix is here equivalent to the Jacobian as it entries G(i,j) are the \nfirst derivative of the i-th datum d(i) with respect to the j-th model parameter m(j). \nWe here refer to the function that calculates the G matrix given a set of model \nparameters as the basis function.\n\nTo take uncertainty into account, we need an extra data covariance matrix C_d having\nthe shape (N,N), where N is the number of data points. Then the formula we try to solve\nis no longer Gm = d, but this instead: (G.T C_d^(-1) G) m = G.T C_d^(-1) d\n    ')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('linear_regression_linear_system_solver.py', 'cofi-examples/examples\\linear_regression\\linear_regression_linear_system_solver.py', 'Polynomial Linear regression solved by linear system solver\n\nThis file sets up an example from setting up problem to running the inversion:\n- For the problem: polynomial linear regression,\n- Using the tool: linear system solver (scipy.linalg.lstsq)\n\nThe function we are going to fit is: y = -6 - 5x + 2x^2 + x^3\n\nWe may also write the polynomial curves in this form: y = sum(m_n * x^n), n=0,1,2,3,\nwhere: m_n, n=0,1,2,3 are the model coefficients.\n\nIf we consider N data points and M=3 model parameters, then N equations like above \nyields a linear operation: d = Gm,\nwhere: d refers to data observations (y_1, y_2, ..., y_N).T\n       G refers to basis matrix: ( (1, x_1, x_1^2, x_1^3)\n                                   (1, x_2, x_2^2, x_2^3)\n                                   ...\n                                   (1, x_N, x_N^2, x_N^3) )\n       m refers to the unknown model parameters (m_0, m_1, m_2, m_3)\n\nNote that G matrix is here equivalent to the Jacobian as it entries G(i,j) are the \nfirst derivative of the i-th datum d(i) with respect to the j-th model parameter m(j). \nWe here refer to the function that calculates the G matrix given a set of model \nparameters as the basis function.\n    ')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('linear_regression_linear_system_general-checkpoint.py', 'cofi-examples/examples\\linear_regression\\.ipynb_checkpoints\\linear_regression_linear_system_general-checkpoint.py', 'Polynomial Linear regression solved by linear system solver (with uncertainty)\n\nThis file sets up an example from setting up problem to running the inversion:\n- For the problem: polynomial linear regression,\n- Using the tool: linear system solver (scipy.linalg.lstsq)\n\nThe difference between this script and linear_regression_linear_system_solver.py\nis that this one takes uncertainty into account, by adding a data covariance matrix.\nThe underlying solver is still scipy.linalg.lstsq, but the formulea passed into it\nare different, as will be explained in the following paragraphs.\n\nThe function we are going to fit is: y = -6 - 5x + 2x^2 + x^3\n\nWe may also write the polynomial curves in this form: y = sum(m_n * x^n), n=0,1,2,3,\nwhere: m_n, n=0,1,2,3 are the model coefficients.\n\nIf we consider N data points and M=3 model parameters, then N equations like above \nyields a linear operation: d = Gm,\nwhere: d refers to data observations (y_1, y_2, ..., y_N).T\n       G refers to basis matrix: ( (1, x_1, x_1^2, x_1^3)\n                                   (1, x_2, x_2^2, x_2^3)\n                                   ...\n                                   (1, x_N, x_N^2, x_N^3) )\n       m refers to the unknown model parameters (m_0, m_1, m_2, m_3)\n\nNote that G matrix is here equivalent to the Jacobian as it entries G(i,j) are the \nfirst derivative of the i-th datum d(i) with respect to the j-th model parameter m(j). \nWe here refer to the function that calculates the G matrix given a set of model \nparameters as the basis function.\n\nTo take uncertainty into account, we need an extra data covariance matrix C_d having\nthe shape (N,N), where N is the number of data points. Then the formula we try to solve\nis no longer Gm = d, but this instead: (G.T C_d^(-1) G) m = G.T C_d^(-1) d\n    ')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('xray_tomography_linear_solver.py', 'cofi-examples/examples\\xray_tomography\\xray_tomography_linear_solver.py', 'Xray tomography problem solved with CoFI linear system solver,\nwith data uncertainty and regularization taken into account.')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Optimization</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Non linear</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('linear_regression_optimizer_lstsq.py', 'cofi-examples/examples\\linear_regression\\linear_regression_optimizer_lstsq.py', 'Polynomial Linear regression solved by an least-squares optimizer\n\nThis file sets up an example from setting up problem to running the inversion:\n- For the problem: polynomial linear regression,\n- Using the tool: non-linear least-squares optimizer (scipy.optimize.least_squares)\n\nThe function we are going to fit is: y = -6 - 5x + 2x^2 + x^3\n\nWe may also write the polynomial curves in this form: y = sum(m_n * x^n), n=0,1,2,3,\nwhere: m_n, n=0,1,2,3 are the model coefficients.\n\nIf we consider N data points and M=3 model parameters, then N equations like above \nyields a linear operation: d = Gm,\nwhere: d refers to data observations (y_1, y_2, ..., y_N).T\n       G refers to basis matrix: ( (1, x_1, x_1^2, x_1^3)\n                                   (1, x_2, x_2^2, x_2^3)\n                                   ...\n                                   (1, x_N, x_N^2, x_N^3) )\n       m refers to the unknown model parameters (m_0, m_1, m_2, m_3)\n\nNote that G matrix is here equivalent to the Jacobian as it entries G(i,j) are the \nfirst derivative of the i-th datum d(i) with respect to the j-th model parameter m(j). \nWe here refer to the function that calculates the G matrix given a set of model \nparameters as the basis function.')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('linear_regression_optimizer_minimize.py', 'cofi-examples/examples\\linear_regression\\linear_regression_optimizer_minimize.py', 'Polynomial Linear regression solved by an optimizer\n\nThis file sets up an example from setting up problem to running the inversion:\n- For the problem: polynomial linear regression,\n- Using the tool: non-linear optimizer (scipy.optimize.minimize)\n\nThe function we are going to fit is: y = -6 - 5x + 2x^2 + x^3\n\nWe may also write the polynomial curves in this form: y = sum(m_n * x^n), n=0,1,2,3,\nwhere: m_n, n=0,1,2,3 are the model coefficients.\n\nIf we consider N data points and M=3 model parameters, then N equations like above \nyields a linear operation: d = Gm,\nwhere: d refers to data observations (y_1, y_2, ..., y_N).T\n       G refers to basis matrix: ( (1, x_1, x_1^2, x_1^3)\n                                   (1, x_2, x_2^2, x_2^3)\n                                   ...\n                                   (1, x_N, x_N^2, x_N^3) )\n       m refers to the unknown model parameters (m_0, m_1, m_2, m_3)\n\nNote that G matrix is here equivalent to the Jacobian as it entries G(i,j) are the \nfirst derivative of the i-th datum d(i) with respect to the j-th model parameter m(j). \nWe here refer to the function that calculates the G matrix given a set of model \nparameters as the basis function.')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('linear_regression_pytorch_optim.py', 'cofi-examples/examples\\linear_regression\\linear_regression_pytorch_optim.py', 'Polynomial Linear regression solved by a PyTorch optimizer\n\nThis file sets up an example from setting up problem to running the inversion:\n- For the problem: polynomial linear regression,\n- Using the tool: non-linear optimizer (pytorch.optim.Adam)\n\nThe function we are going to fit is: y = -6 - 5x + 2x^2 + x^3\n\nWe may also write the polynomial curves in this form: y = sum(m_n * x^n), n=0,1,2,3,\nwhere: m_n, n=0,1,2,3 are the model coefficients.\n\nIf we consider N data points and M=3 model parameters, then N equations like above \nyields a linear operation: d = Gm,\nwhere: d refers to data observations (y_1, y_2, ..., y_N).T\n       G refers to basis matrix: ( (1, x_1, x_1^2, x_1^3)\n                                   (1, x_2, x_2^2, x_2^3)\n                                   ...\n                                   (1, x_N, x_N^2, x_N^3) )\n       m refers to the unknown model parameters (m_0, m_1, m_2, m_3)\n\nNote that G matrix is here equivalent to the Jacobian as it entries G(i,j) are the \nfirst derivative of the i-th datum d(i) with respect to the j-th model parameter m(j). \nWe here refer to the function that calculates the G matrix given a set of model \nparameters as the basis function.')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linear</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('linear_regression_emcee_sampler.py', 'cofi-examples/examples\\linear_regression\\linear_regression_emcee_sampler.py', 'Polynomial Linear regression solved by sampler with emcee\n\nThis file sets up an example from setting up problem to running the inversion:\n- For the problem: polynomial linear regression,\n- Using the tool: Bayesian sampler (emcee)\n\nThe function we are going to fit is: y = -6 - 5x + 2x^2 + x^3\n\nWe may also write the polynomial curves in this form: y = sum(m_n * x^n), n=0,1,2,3,\nwhere: m_n, n=0,1,2,3 are the model coefficients.\n\nIf we consider N data points and M=3 model parameters, then N equations like above \nyields a linear operation: d = Gm,\nwhere: d refers to data observations (y_1, y_2, ..., y_N).T\n       G refers to basis matrix: ( (1, x_1, x_1^2, x_1^3)\n                                   (1, x_2, x_2^2, x_2^3)\n                                   ...\n                                   (1, x_N, x_N^2, x_N^3) )\n       m refers to the unknown model parameters (m_0, m_1, m_2, m_3)\n\nNote that G matrix is here equivalent to the Jacobian as it entries G(i,j) are the \nfirst derivative of the i-th datum d(i) with respect to the j-th model parameter m(j). \nWe here refer to the function that calculates the G matrix given a set of model \nparameters as the basis function.')</li><li>&nbsp;&nbsp;&nbsp;Ensemble methods</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Direct Search</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Monte Carlo</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Deterministic</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bayesian Sampling</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;McMC samplers</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('emcee_parallel_bad_practice.py', 'cofi-examples/examples\\more_scripts\\emcee_parallel_bad_practice.py', 'This script demonstrates the "bad" practice for a simple parallel example.\n\nCode in this file is adapted from emcee documentation. And we intend to deal with the\nexact issue described here:\nhttps://emcee.readthedocs.io/en/stable/tutorials/parallel/#pickling-data-transfer-arguments\n\nCompared to the file emcee_parallel_good_practice.py (in the same folder), the "data" \nargument is an argument of log probability function instead of being global.\n\nAs you run this file and you will see, the speed decreases when it\'s in parallel.')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('emcee_parallel_good_practice.py', 'cofi-examples/examples\\more_scripts\\emcee_parallel_good_practice.py', 'This script demonstrates the "good" practice for a simple parallel example.\n\nCode in this file is adapted from emcee documentation. And we intend to deal with the\nexact issue described here:\nhttps://emcee.readthedocs.io/en/stable/tutorials/parallel/#pickling-data-transfer-arguments\n\nCompared to the file emcee_parallel_bad_practice.py (in the same folder), the "data" \nargument is set to be global instead of being an argument of log probability function.\n\nAs you run this file and you will see, the speed increases when it\'s in parallel.')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;('pygimli_ert_rect_emcee.py', 'cofi-examples/examples\\pygimli_ert\\archived\\pygimli_ert_rect_emcee.py', 'Eletrical Resistivity Tomography Inversion with PyGIMLi + CoFI\n\nThis script runs:\n- ERT problem (rectangular mesh) defined with PyGIMLi, and\n- Bayesian sampling using emcee with CoFI\n\n\nTo run this script, refer to the following examples:\n\n- `python pygimli_ert_rect_emcee.py` for a simple run, with all the figures saved to\n  current directory by default\n\n- `python pygimli_ert_rect_emcee.py -o figs` for the same run as above, with all the\n  figures saved to subfolder `figs`\n\n- `python pygimli_ert_rect_emcee.py -h` to see all available options')</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Trans-D McMC</li></ul></body></html>